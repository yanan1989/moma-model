num_crops: 3
num_clips: 10
T: 8
tau: 8
# Reference: https://github.com/facebookresearch/pytorchvideo/blob/main/pytorchvideo_trainer/pytorchvideo_trainer/conf/datamodule/transforms/kinetics_classification_slowfast.yaml
transform:
  train:
    _target_: pytorchvideo.transforms.ApplyTransformToKey
    key: video
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: pytorchvideo.transforms.UniformTemporalSubsample
          num_samples: 32  # T*alpha
        - _target_: pytorchvideo.transforms.Div255
        - _target_: pytorchvideo.transforms.Normalize
          mean: [0.45, 0.45, 0.45]
          std: [0.225, 0.225, 0.225]
        - _target_: pytorchvideo.transforms.RandomShortSideScale
          min_size: 256
          max_size: 320
        - _target_: torchvision.transforms.RandomCrop
          size: 224
        - _target_: torchvision.transforms.RandomHorizontalFlip
          p: 0.5
        - _target_: pytorchvideo_trainer.datamodule.transforms.SlowFastPackPathway
          alpha: 4
  val:
    _target_: pytorchvideo.transforms.ApplyTransformToKey
    key: video
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: pytorchvideo.transforms.UniformTemporalSubsample
          num_samples: 32  # T*alpha
        - _target_: pytorchvideo.transforms.Div255
        - _target_: pytorchvideo.transforms.Normalize
          mean: [0.45, 0.45, 0.45]
          std: [0.225, 0.225, 0.225]
        - _target_: pytorchvideo.transforms.ShortSideScale
          size: 256
        - _target_: torchvision.transforms.CenterCrop
          size: 256
        - _target_: pytorchvideo_trainer.datamodule.transforms.SlowFastPackPathway
          alpha: 4