dataset:
  num_crops: 3
  num_clips: 10
  T: 8
  tau: 8
  # Reference: https://github.com/facebookresearch/pytorchvideo/blob/main/pytorchvideo_trainer/pytorchvideo_trainer/conf/datamodule/transforms/kinetics_classification_slowfast.yaml
  transform:
    train:
      _target_: pytorchvideo.transforms.ApplyTransformToKey
      key: video
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
          - _target_: pytorchvideo.transforms.UniformTemporalSubsample
            num_samples: 32  # T*alpha
          - _target_: pytorchvideo.transforms.Div255
          - _target_: pytorchvideo.transforms.Normalize
            mean: ${data.dataset.transform.mean}
            std: ${data.dataset.transform.std}
          - _target_: pytorchvideo.transforms.RandomShortSideScale
            min_size: 256
            max_size: 320
          - _target_: torchvision.transforms.RandomCrop
            size: 224
          - _target_: torchvision.transforms.RandomHorizontalFlip
            p: 0.5
          - _target_: data.transforms.SlowFastPackPathway
            alpha: 4
    val:
      _target_: pytorchvideo.transforms.ApplyTransformToKey
      key: video
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
          - _target_: pytorchvideo.transforms.UniformTemporalSubsample
            num_samples: 32  # T*alpha
          - _target_: pytorchvideo.transforms.Div255
          - _target_: pytorchvideo.transforms.Normalize
            mean: ${data.dataset.transform.mean}
            std: ${data.dataset.transform.std}
          - _target_: pytorchvideo.transforms.ShortSideScale
            size: 256
          - _target_: torchvision.transforms.CenterCrop
            size: 256
          - _target_: data.transforms.SlowFastPackPathway
            alpha: 4